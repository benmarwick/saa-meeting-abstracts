---
title: "The Geometry of Archaeological Thought: Analysing discplinary change using word embeddings from conference abstracts"
output: bookdown::html_document2
bibliography: references.bib
date: "`r format(Sys.time(), '%d %B, %Y')`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

BM: The study of disciplinary change traditionally relies on close reading of a large number of publications, manually sorting them into pre-defined categories and making connections between these groups and external influences [e.g. @trigger1989history]. These methods are time-consuming and expensive (because they depend on full access to a large library of texts), which limits participation in this aspect of archaeology. Computational approaches to analyzing text that can process many publications quickly to generate topics in a bottom-up fashion offer a new way to investigate disciplinary history. This has the advantage of increasing and diversifying participation in study of the history of archaeology, as well as  more comprehensive, systematic, and reproducible analyses of the contents of large number of full-text documents. The methods and data we present here offer empirical basis for what might otherwise be informal claims about the discipline and its history. They are also the type of data that may prompt discussion about the directions the discipline might — or could — take.

BM: In this paper we present a dataset of all available abstracts of papers and posters presented at annual meetings of the Society of American Archaeology. We demonstrate the use of word embeddings, a commonly used computational tool in natural language processing (NLP) and machine learning, as a method to measure, quantify, and compare changes in the way archaeologists write cf. [@Garg2018; @Kozlowski2019]. We present the temporal reference plot as a method for visualizing disciplinary change in archaeology. As a case study, we use these data and methods to explore how archaeologists' writing about explaining and theorizing the past have changed over time.

# Background

BM: Research into the history of archaeology is often organised into two major phases. An early internalist phase, where the story of development of the field is told with limited reference to the influence of political, social, religious, and economic institutions. In the 1980s an external, critical history phase began, seeking to understand the interactions between archaeological practice and its political, economic and social contexts.

BM: Among historians of archaeology there are two major phases in  ‘critical history of archaeology’ in the 1980s had been characterized by the replacement of an 

- previous efforts at the history of archaeology (e.g. Bruce Trigger's book)
- previous efforts at text analysis in archaeology (e.g. bibliometrics, citation networks)
- new phase: we are now in the third phase  - computational text analysis
- one promising new method is WE... successful applications of WE in other fields... 

- background to Word embeddings

LW: Word embeddings are an effective way to analyze the temporal changes of any target word. A word embedding is a set of numbers that characterizes the meaning a word. Word embeddings are generated on a collection of texts, and can be used for calculation of the semantic relationships between words according to their distance in the texts. We can see how the meaning of a word shifts over time by visualizing the word embeddings and observing how the word moves through different spaces occupied by other words over time. When a word is in close proximity to other words, they have a high degree of semantic relatedness. This method allows for the exploration of the changing meaning of words in different contexts. For example, @Garg2018 explored changes in gender stereotypes and attitudes toward ethnic minorities in the 20th and 21st centuries in the US. They created custom lists of target words representing gender and ethnicity, and neutral words, such as adjectives and jobs, serving as indicators for stereotypes and attitudes. <!--where did their word embeddings come from, and what algorithm did they use? --> With word embeddings, they compared the association between each group <!--what is the group? we need to mention the groups before this sentence --> and neutral words, where the strength of association is calculated by computing average embedding distance. They found there is a job bias for both gender and ethnic minority, <!-- we really need a concrete example here --> this bias is significantly correlated with the actual job participation rates. In addition, there is a decreases in bias reflected by adjectives for ethnic minority and gender are associated with the women’s movement in the 1960s–1970s and Asian-American population growth in the 1960s and 1980s <!--"Another bias they identified was ... give the reader a concrete result from the paper  -->. This study demonstrates a successful application of word embeddings to detect social bias <!-- can we re-prhase to be about changing meanings of words? --> and correlate the findings with historical events.

LW: Another example shows how word embeddings are effective <!-- Q: for what? A: for understanding semantic change over time --> by exploring the historical view on shared understandings of social classes in the 20th century in the US. @Kozlowski first compared the cultural dimensions created by word embeddings <!-- generated word embeddings from what data? and what algorithm did they use? --> with a defined word list reflecting socio-economic differences, such as 'rich', 'poor' and so on. The high association <!-- of what? between what? --> suggests that word embedding is a useful way to investigate people's views about social classes. They explored the relationship between dimensions of class identified in sociological theory, including morality, status, education, cultivation, gender, and employment. They found there is a high correlation <!-- of what? spell it out if this is about the word vectors, say --> between dimensions of education, cultivation, and morality, which corresponds to the owner/worker relation <!-- what relation? spell out more --> defined by classic Marxism. In addition, they found a stable relationship between different cultural dimensions of class over the century even though there was a major shift in the condition of economy, industry, and employment in the present day. This case study indicates the robustness of word embeddings as a method to examine historical trends of social classes. 

# Methods

```{r read-data}
saa_data <- readxl::read_excel(here::here("data", "raw-data", "saa-abstracts-tally.xlsx"))

# basic stats
library(tidyverse)
abstract_num <- sum(saa_data$number_of_abstracts, na.rm = TRUE)
year_num <- length(which(!is.na(saa_data$number_of_abstracts))) # 41 years

# get all txt files of abstracts
abstract_txt_files <- 
  fs::dir_ls(here::here("data/derived-data/"), 
             recurse = TRUE, 
             regexp = '\\.txt$')
all_txts <- tolower(readtext::readtext(abstract_txt_files))

all_word_counts <- sum(stringi::stri_count_words(all_txts))
```

LW: The data for our study comes from the text of abstracts of oral and poster presentations at the annual meetings of the Society of American Archaeology (SAA). The earliest meeting in our data is 1962, and we have some years missing, especially 1995-2003 where PDF files were not available to us. The total number of abstracts is `r prettyNum(abstract_num, big.mark = ",")` (`r prettyNum(all_word_counts, big.mark = ",")` words) from `r year_num` annual meetings. We obtained PDF files of annual programs from https://www.saa.org/annual-meeting/annual-meeting-archives/program-archives. 

LW: The PDFs for the years 1962-1994 contain images of pages, and after 2005 the PDFs are searchable text. We converted the page images from PDF to PNG files using ImageMagick software, and then used optical character recognition to extract text from the PNG files with the Tesseract package [@Kay2007]. We obtained an acceptable rate of 95-98% word-level OCR accuracy across the PDFs [@Holley2009]. After OCR, we removed punctuation, numbers, and stopwords, such as "the", "an", "a", due to their little or no semantic value for our research question, with the quanteda package [@Benoit2018]. 

LW: We transformed the cleaned text into a document-feature matrix. This is a rectangular, tabular data structure where one row represents one PDF, and one column represents one word, also known as a feature. The cell values in this matrix are the frequencies of each feature for each PDF. We selected the features that occur at least three times across all PDFs for construction of a feature co-occurrence matrix. To create this matrix we calculated how often each feature appears with another. The co-occurrences are measured within a defined range of surrounding words, known as a window, with the target feature in the middle position and context features before and after it. Here we set the range to five, meaning five words before and five words after the target feature, as our framework for calculating the co-occurrence counts. 

LW: We generated the word embeddings on the co-occurrence matrix using the GloVe algorithm from the text2vec package for R [@Pennington2014; @Selivanov2016]. GloVe (Global Vectors) is a unsupervised learning model that creates word vectors to represent semantic regularity and capture relationships between words [@Pennington2014; @Garg2018]. This idea is similar to the concept of Principal Component Analysis (PCA) that reduces a multi-dimensional dataset into a small number of new dimensions that usually capture most of the variation in the data. In this case, a word vector is similar to a principal component because it expresses the meaning of the word into a small set of numeric values. The more values in this set, or the more dimensions, the more accurately semantic meanings of a word can be captured. In our case, we use 50 dimensions. One of the most interesting qualities of word vectors is that simple arithmetic operations can reveal semantic relationships between words [@mikolov2013linguistic]. For example if we subtract the word vector values for 'man' from the word vector values for 'king', and add the word vector values for 'woman', the resulting vector will be very close to that of 'queen', such that we can literally compute queen = king - man + woman.

<!-- one paragraph of plain and simple description of how Glove computes word vectors from co-oc matrix -->

LW: We then visualize the values across different dimensions to explore the historical trend of word meanings related to disciplinary change in archaeology. 

<!-- one paragraph of explaining how did we choose these words -->

We created a word list, including theory, inference, mechanism, explanation, hypothesis, to explore how they changes in their meaning or use since 1962. We compare the word embeddings at a interval of ten years.





<!-- There are two major word-level pretrained word embeddings, Word2Vec and Glove according to different methods used for training [@Rong2014; @Pennington2014]. --> 




```{r temporal-referencing-plots, cache.extra=tools::md5sum(here::here("006-testing-word-2-vec-temporal-referencing-by-period.R"))}
source(here::here("code/006-testing-word-2-vec-temporal-referencing-by-period.R"))
```


- basic details (e.g. word and abstract counts)
- word frequency time series
- TR plots

# Discussion

- ...

# Conclusion

- ...

# Acknowledgements

# References 

<!--- use the bib file --> 



